{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807072f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup -- preview\n",
    "# Import necessary libraries and define the base path for the data files.\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161ce935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path to your raw data directory\n",
    "# IMPORTANT: Make sure this path is correct for your system.\n",
    "base_path = '/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286cee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading GDP Data ---\n",
      "Successfully loaded GDP data.\n",
      "First 5 rows of GDP data:\n",
      "                  Country Name Country Code     Indicator Name  \\\n",
      "0                        Aruba          ABW  GDP (current US$)   \n",
      "1  Africa Eastern and Southern          AFE  GDP (current US$)   \n",
      "2                  Afghanistan          AFG  GDP (current US$)   \n",
      "3   Africa Western and Central          AFW  GDP (current US$)   \n",
      "4                       Angola          AGO  GDP (current US$)   \n",
      "\n",
      "   Indicator Code          1960          1961          1962          1963  \\\n",
      "0  NY.GDP.MKTP.CD           NaN           NaN           NaN           NaN   \n",
      "1  NY.GDP.MKTP.CD  2.420993e+10  2.496326e+10  2.707802e+10  3.177483e+10   \n",
      "2  NY.GDP.MKTP.CD           NaN           NaN           NaN           NaN   \n",
      "3  NY.GDP.MKTP.CD  1.190511e+10  1.270803e+10  1.363092e+10  1.446926e+10   \n",
      "4  NY.GDP.MKTP.CD           NaN           NaN           NaN           NaN   \n",
      "\n",
      "           1964          1965  ...          2016          2017          2018  \\\n",
      "0           NaN           NaN  ...  2.983635e+09  3.092429e+09  3.276184e+09   \n",
      "1  3.028492e+10  3.381219e+10  ...  8.289612e+11  9.730251e+11  1.012291e+12   \n",
      "2           NaN           NaN  ...  1.811657e+10  1.875346e+10  1.805322e+10   \n",
      "3  1.580394e+10  1.692124e+10  ...  7.000282e+11  6.940513e+11  7.778404e+11   \n",
      "4           NaN           NaN  ...  5.276162e+10  7.369015e+10  7.945069e+10   \n",
      "\n",
      "           2019          2020          2021          2022          2023  \\\n",
      "0  3.395799e+09  2.481857e+09  2.929447e+09  3.279344e+09  3.648573e+09   \n",
      "1  1.009747e+12  9.334072e+11  1.085605e+12  1.191639e+12  1.133818e+12   \n",
      "2  1.879944e+10  1.995593e+10  1.426000e+10  1.449724e+10  1.715223e+10   \n",
      "3  8.332889e+11  7.972952e+11  8.581145e+11  8.936399e+11  8.147285e+11   \n",
      "4  7.089796e+10  4.850156e+10  6.650513e+10  1.043997e+11  8.487516e+10   \n",
      "\n",
      "           2024  Unnamed: 69  \n",
      "0           NaN          NaN  \n",
      "1  1.205974e+12          NaN  \n",
      "2           NaN          NaN  \n",
      "3  6.700257e+11          NaN  \n",
      "4  8.039694e+10          NaN  \n",
      "\n",
      "[5 rows x 70 columns]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Load GDP Data\n",
    "# Load the world GDP data from api_ny_gdp_mktp_cd_ds2.csv.\n",
    "print(\"--- Loading GDP Data ---\")\n",
    "gdp_file_path = os.path.join(base_path, 'api_ny_gdp_mktp_cd_ds2.csv')\n",
    "\n",
    "try:\n",
    "    # We skip the first 4 rows which contain metadata, not the actual data.\n",
    "    df_gdp = pd.read_csv(gdp_file_path, skiprows=4)\n",
    "    print(\"Successfully loaded GDP data.\")\n",
    "    print(\"First 5 rows of GDP data:\")\n",
    "    print(df_gdp.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: GDP file not found at {gdp_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eecb887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Countries Shapefile ---\n",
      "Successfully loaded countries shapefile.\n",
      "First 5 rows of the shapefile data:\n",
      "  ADM0_A3  abbrev continent                    formal_nam iso_a2 iso_a3  \\\n",
      "0     AFG    Afg.      Asia  Islamic State of Afghanistan     AF    AFG   \n",
      "1     AGO    Ang.    Africa   People's Republic of Angola     AO    AGO   \n",
      "2     ALB    Alb.    Europe           Republic of Albania     AL    ALB   \n",
      "3     AND    And.    Europe       Principality of Andorra     AD    AND   \n",
      "4     ARE  U.A.E.      Asia          United Arab Emirates     AE    ARE   \n",
      "\n",
      "   iso_n3                   iso_short                  name  \\\n",
      "0       4                 Afghanistan           Afghanistan   \n",
      "1      24                      Angola                Angola   \n",
      "2       8                     Albania               Albania   \n",
      "3      20                     Andorra               Andorra   \n",
      "4     784  United Arab Emirates (the)  United Arab Emirates   \n",
      "\n",
      "              name_sort  ...                      un_fr  un_n3 un_region  \\\n",
      "0           Afghanistan  ...   Afghanistan (l') [masc.]      4      Asia   \n",
      "1                Angola  ...        Angola (l') [masc.]     24    Africa   \n",
      "2               Albania  ...        Albanie (l') [fém.]      8    Europe   \n",
      "3               Andorra  ...        Andorre (l') [fém.]     20    Europe   \n",
      "4  United Arab Emirates  ...  Émirats arabes unis (les)    784      Asia   \n",
      "\n",
      "                           un_ru       un_subregi     un_zh wb_a2 wb_a3  \\\n",
      "0                     Афганистан    Southern Asia       阿富汗    AF   AFG   \n",
      "1                         Ангола    Middle Africa       安哥拉    AO   AGO   \n",
      "2                        Албания  Southern Europe     阿尔巴尼亚    AL   ALB   \n",
      "3                        Андорра  Southern Europe       安道尔    AD   ADO   \n",
      "4  Объединенные Арабские Эмираты     Western Asia  阿拉伯联合酋长国    AE   ARE   \n",
      "\n",
      "                    wb_region  \\\n",
      "0                  South Asia   \n",
      "1          Sub-Saharan Africa   \n",
      "2       Europe & Central Asia   \n",
      "3       Europe & Central Asia   \n",
      "4  Middle East & North Africa   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((74.89231 37.23111, 74.81314 37.21543...  \n",
      "1  MULTIPOLYGON (((11.73752 -16.69258, 11.73851 -...  \n",
      "2  POLYGON ((20.06496 42.54676, 20.08563 42.53001...  \n",
      "3  POLYGON ((1.70701 42.50278, 1.6975 42.49446, 1...  \n",
      "4  MULTIPOLYGON (((53.86305 24.23469, 53.8886 24....  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Load Countries Shapefile\n",
    "# Load the country boundaries from the shapefile.\n",
    "print(\"--- Loading Countries Shapefile ---\")\n",
    "shapefile_path = os.path.join(base_path, 'countries_shapefile', 'cn_primary_countries.shp')\n",
    "\n",
    "try:\n",
    "    gdf_countries = gpd.read_file(shapefile_path)\n",
    "    print(\"Successfully loaded countries shapefile.\")\n",
    "    print(\"First 5 rows of the shapefile data:\")\n",
    "    print(gdf_countries.head())\n",
    "except Exception as e:\n",
    "    # Using a general exception as geopandas can have various backend errors\n",
    "    print(f\"Error loading shapefile: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c34f0da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Trade Data ---\n",
      "- An error occurred while loading baci_hs12_y2016_v202001.csv: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n",
      "- Successfully loaded baci_hs12_y2017_v202001.csv\n",
      "- Successfully loaded baci_hs12_y2018_v202001.csv\n",
      "- An error occurred while loading country_codes_v202001.csv: 'utf-8' codec can't decode byte 0xf4 in position 4141: invalid continuation byte\n",
      "- Successfully loaded product_codes_hs12_v202001.csv\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Load Trade Data\n",
    "# Load the various trade-related datasets from the `trade_data` directory.\n",
    "print(\"--- Loading Trade Data ---\")\n",
    "trade_data_path = os.path.join(base_path, 'trade_data')\n",
    "trade_files = [\n",
    "    'baci_hs12_y2016_v202001.csv',\n",
    "    'baci_hs12_y2017_v202001.csv',\n",
    "    'baci_hs12_y2018_v202001.csv',\n",
    "    'country_codes_v202001.csv',\n",
    "    'product_codes_hs12_v202001.csv'\n",
    "]\n",
    "\n",
    "# A dictionary to hold all the loaded trade dataframes\n",
    "trade_dataframes = {}\n",
    "\n",
    "for file in trade_files:\n",
    "    file_path = os.path.join(trade_data_path, file)\n",
    "    # Use a clean name for the dictionary key (e.g., 'baci_hs12_y2016_v202001')\n",
    "    df_name = file.split('.')[0]\n",
    "    try:\n",
    "        trade_dataframes[df_name] = pd.read_csv(file_path)\n",
    "        print(f\"- Successfully loaded {file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"- Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"- An error occurred while loading {file}: {e}\")\n",
    "\n",
    "# You can now access each dataframe from the dictionary, for example:\n",
    "if 'country_codes_v202001' in trade_dataframes:\n",
    "    print(\"\\nExample: First 5 rows of country_codes_v202001.csv:\")\n",
    "    print(trade_dataframes['country_codes_v202001'].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bffdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Optional: Combine yearly trade data\n",
    "# If the yearly BACI trade files have the same columns, we can combine them.\n",
    "print(\"--- Combining yearly BACI trade data ---\")\n",
    "baci_trade_dfs_to_combine = []\n",
    "for key, df in trade_dataframes.items():\n",
    "    if 'baci_hs12_y' in key:\n",
    "        baci_trade_dfs_to_combine.append(df)\n",
    "\n",
    "if baci_trade_dfs_to_combine:\n",
    "    df_baci_combined = pd.concat(baci_trade_dfs_to_combine, ignore_index=True)\n",
    "    print(\"Successfully combined yearly BACI trade data into a single DataFrame.\")\n",
    "    print(f\"Total rows in combined data: {len(df_baci_combined)}\")\n",
    "    print(\"\\nFirst 5 rows of combined BACI data:\")\n",
    "    print(df_baci_combined.head())\n",
    "    print(\"\\nLast 5 rows of combined BACI data:\")\n",
    "    print(df_baci_combined.tail())\n",
    "else:\n",
    "    print(\"No BACI dataframes were found to combine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Q1a. Setup and Data Loading ---\n",
    "# This version adds the encoding='latin1' parameter to handle the file encoding error.\n",
    "\n",
    "# Define the base path to your raw data directory\n",
    "base_path = '/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw'\n",
    "trade_data_path = os.path.join(base_path, 'trade_data')\n",
    "\n",
    "# A dictionary to hold the loaded dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# List of files to load\n",
    "files_to_load = [\n",
    "    'baci_hs12_y2016_v202001.csv',\n",
    "    'baci_hs12_y2017_v202001.csv',\n",
    "    'baci_hs12_y2018_v202001.csv',\n",
    "    'country_codes_v202001.csv'\n",
    "]\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "for file in files_to_load:\n",
    "    file_path = os.path.join(trade_data_path, file)\n",
    "    df_name = file.split('.')[0]\n",
    "    try:\n",
    "        # THE FIX IS HERE: Added encoding='latin1' to handle non-UTF-8 characters\n",
    "        dataframes[df_name] = pd.read_csv(file_path, on_bad_lines='skip', encoding='latin1')\n",
    "        print(f\"- Successfully loaded {file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"- Error: File not found at {file_path}\")\n",
    "        exit()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while loading {file}: {e}\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "# Combine the three years of trade data into one DataFrame\n",
    "baci_dfs = [df for name, df in dataframes.items() if 'baci_hs12_y' in name]\n",
    "if not baci_dfs:\n",
    "    print(\"Error: No BACI trade data files were loaded. Cannot proceed.\")\n",
    "    exit()\n",
    "\n",
    "df_trade_combined = pd.concat(baci_dfs, ignore_index=True)\n",
    "print(\"\\nCombined 2016-2018 trade data successfully.\\n\")\n",
    "\n",
    "# Load country codes for mapping codes to names\n",
    "df_country_codes = dataframes.get('country_codes_v202001')\n",
    "if df_country_codes is None:\n",
    "    print(\"Error: country_codes_v202001.csv could not be loaded. Cannot map country names.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Calculate Trading Partners for Each Country ---\n",
    "# The logic here remains the same as before.\n",
    "\n",
    "# Get a list of all unique country codes present in the trade data\n",
    "all_country_codes = pd.unique(df_trade_combined[['i', 'j']].values.ravel('K'))\n",
    "\n",
    "partner_counts = {}\n",
    "\n",
    "for code in all_country_codes:\n",
    "    # Find all countries this country exported to\n",
    "    exports_to = set(df_trade_combined[df_trade_combined['i'] == code]['j'])\n",
    "    \n",
    "    # Find all countries this country imported from\n",
    "    imports_from = set(df_trade_combined[df_trade_combined['j'] == code]['i'])\n",
    "    \n",
    "    # The set of unique partners is the union of the two sets\n",
    "    unique_partners = exports_to.union(imports_from)\n",
    "    \n",
    "    # Count the number of partners and store it\n",
    "    partner_counts[code] = len(unique_partners)\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame for easier sorting and merging\n",
    "df_partner_counts = pd.DataFrame(list(partner_counts.items()), columns=['country_code', 'partner_count'])\n",
    "\n",
    "# Merge with the country names for a readable output\n",
    "if 'country_name_full' in df_country_codes.columns and 'country_code' in df_country_codes.columns:\n",
    "    df_results = pd.merge(df_partner_counts, df_country_codes[['country_code', 'country_name_full']], on='country_code', how='left')\n",
    "    df_results = df_results.sort_values(by='partner_count', ascending=False).reset_index(drop=True)\n",
    "    df_results = df_results.rename(columns={'country_name_full': 'country_name'})\n",
    "else:\n",
    "    print(\"Country code file does not have expected columns 'country_code' and 'country_name_full'. Cannot display full names.\")\n",
    "    df_results = df_partner_counts.sort_values(by='partner_count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- 3. Display Descriptive Statistics ---\n",
    "\n",
    "print(\"\\n--- Descriptive Statistics: Trading Partners (2016-2018) ---\\n\")\n",
    "\n",
    "# Top 10 Countries with the Most Trading Partners\n",
    "print(\"Top 10 Countries with the Most Trading Partners:\")\n",
    "# Fill potential missing names with the code for robustness\n",
    "df_results['country_name'] = df_results['country_name'].fillna('Unknown')\n",
    "top_10 = df_results.head(10)\n",
    "print(top_10[['country_name', 'partner_count']].to_string(index=False))\n",
    "\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "\n",
    "# Bottom 10 Countries with the Fewest Trading Partners\n",
    "print(\"Bottom 10 Countries with the Fewest Trading Partners:\")\n",
    "bottom_10 = df_results[df_results['partner_count'] > 0].tail(10)\n",
    "print(bottom_10[['country_name', 'partner_count']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Q1b. Setup and Data Loading (Including Product Codes) ---\n",
    "\n",
    "# Define the base path to your raw data directory\n",
    "base_path = '/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw'\n",
    "trade_data_path = os.path.join(base_path, 'trade_data')\n",
    "\n",
    "# A dictionary to hold the loaded dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# List of all necessary files\n",
    "files_to_load = [\n",
    "    'baci_hs12_y2016_v202001.csv',\n",
    "    'baci_hs12_y2017_v202001.csv',\n",
    "    'baci_hs12_y2018_v202001.csv',\n",
    "    'country_codes_v202001.csv',\n",
    "    'product_codes_hs12_v202001.csv'\n",
    "]\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "for file in files_to_load:\n",
    "    file_path = os.path.join(trade_data_path, file)\n",
    "    df_name = file.split('.')[0]\n",
    "    try:\n",
    "        # Use encoding='latin1' to prevent UnicodeDecodeError\n",
    "        dataframes[df_name] = pd.read_csv(file_path, on_bad_lines='skip', encoding='latin1')\n",
    "        print(f\"- Successfully loaded {file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"- Error: File not found at {file_path}\")\n",
    "        exit()\n",
    "\n",
    "# Combine the yearly trade data\n",
    "baci_dfs = [df for name, df in dataframes.items() if 'baci_hs12_y' in name]\n",
    "if not baci_dfs:\n",
    "    print(\"Error: No BACI trade data files were loaded. Cannot proceed.\")\n",
    "    exit()\n",
    "df_trade_combined = pd.concat(baci_dfs, ignore_index=True)\n",
    "print(\"\\nCombined 2016-2018 trade data successfully.\")\n",
    "\n",
    "# Prepare code-to-name mapping tables\n",
    "df_country_codes = dataframes.get('country_codes_v202001')\n",
    "df_product_codes = dataframes.get('product_codes_hs12_v202001')\n",
    "\n",
    "if df_country_codes is None or df_product_codes is None:\n",
    "    print(\"Error: Code description files could not be loaded.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Describe Overall Trade Volume ---\n",
    "\n",
    "print(\"\\n--- Overall Trade Volume Description (2016-2018) ---\")\n",
    "# The trade value 'v' is in thousands of US dollars.\n",
    "total_trade_value = df_trade_combined['v'].sum()\n",
    "print(f\"Total Global Trade Value (sum of all flows): ${total_trade_value:,.0f} thousand USD\")\n",
    "\n",
    "print(\"\\nDescriptive Statistics for Trade Value ('v') per flow:\")\n",
    "# Using describe() to get a statistical summary\n",
    "description = df_trade_combined['v'].describe()\n",
    "# Format the output for readability\n",
    "for idx, val in description.items():\n",
    "    print(f\"{idx.capitalize():>8}: {val:,.2f}\")\n",
    "\n",
    "\n",
    "# --- 3. Identify Top 10 Partners for China and the USA ---\n",
    "\n",
    "print(\"\\n\\n--- Top 10 Trading Partners by Total Value (2016-2018) ---\")\n",
    "\n",
    "def get_top_10_partners(country_name_str, country_codes_df, trade_df):\n",
    "    \"\"\"Calculates and prints the top 10 trading partners for a given country.\"\"\"\n",
    "    try:\n",
    "        country_code = int(country_codes_df[country_codes_df['country_name_full'].str.contains(country_name_str, na=False)].iloc[0]['country_code'])\n",
    "    except (IndexError, TypeError):\n",
    "        print(f\"Could not find country code for '{country_name_str}'.\")\n",
    "        return\n",
    "\n",
    "    # Filter for all trade involving the country (as exporter 'i' or importer 'j')\n",
    "    country_trade_df = trade_df[(trade_df['i'] == country_code) | (trade_df['j'] == country_code)].copy()\n",
    "    \n",
    "    # Determine the partner code for each transaction\n",
    "    country_trade_df['partner_code'] = country_trade_df.apply(\n",
    "        lambda row: row['j'] if row['i'] == country_code else row['i'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Group by partner and sum the trade value\n",
    "    partner_trade = country_trade_df.groupby('partner_code')['v'].sum().reset_index()\n",
    "    \n",
    "    # Merge with country names to get partner names\n",
    "    partner_trade = pd.merge(partner_trade, country_codes_df[['country_code', 'country_name_full']], left_on='partner_code', right_on='country_code', how='left')\n",
    "    \n",
    "    # Sort to find the top partners\n",
    "    top_10 = partner_trade.sort_values(by='v', ascending=False).head(10)\n",
    "    \n",
    "    print(f\"\\nTop 10 Partners for {country_name_str}:\")\n",
    "    top_10['v_formatted'] = top_10['v'].apply(lambda x: f\"${x:,.0f}K\")\n",
    "    print(top_10[['country_name_full', 'v_formatted']].rename(columns={'country_name_full': 'Partner Country', 'v_formatted': 'Total Trade Value'}).to_string(index=False))\n",
    "\n",
    "# Run the function for China and the United States\n",
    "get_top_10_partners(\"China\", df_country_codes, df_trade_combined)\n",
    "get_top_10_partners(\"United States of America\", df_country_codes, df_trade_combined)\n",
    "\n",
    "\n",
    "# --- 4. List the Five Highest-Value China Trade Flows ---\n",
    "\n",
    "print(\"\\n\\n--- Five Highest-Value China Trade Flows (2016-2018) ---\")\n",
    "\n",
    "try:\n",
    "    china_code = int(df_country_codes[df_country_codes['country_name_full'].str.contains(\"China\", na=False)].iloc[0]['country_code'])\n",
    "\n",
    "    # Filter for all trade involving China\n",
    "    china_trade_df = df_trade_combined[(df_trade_combined['i'] == china_code) | (df_trade_combined['j'] == china_code)]\n",
    "\n",
    "    # Group by the specific flow (exporter and importer) and sum the value\n",
    "    flow_values = china_trade_df.groupby(['i', 'j'])['v'].sum().reset_index()\n",
    "    \n",
    "    # Sort to find the highest-value flows\n",
    "    top_flows = flow_values.sort_values(by='v', ascending=False).head(5)\n",
    "\n",
    "    # Merge to get exporter names\n",
    "    top_flows = pd.merge(top_flows, df_country_codes[['country_code', 'country_name_full']], left_on='i', right_on='country_code', how='left')\n",
    "    top_flows = top_flows.rename(columns={'country_name_full': 'Exporter'})\n",
    "    \n",
    "    # Merge to get importer names\n",
    "    top_flows = pd.merge(top_flows, df_country_codes[['country_code', 'country_name_full']], left_on='j', right_on='country_code', how='left')\n",
    "    top_flows = top_flows.rename(columns={'country_name_full': 'Importer'})\n",
    "    \n",
    "    # Format for printing\n",
    "    top_flows['Total Value'] = top_flows['v'].apply(lambda x: f\"${x:,.0f}K\")\n",
    "\n",
    "    print(\"Top 5 individual trade flows involving China (sum of all products and years):\")\n",
    "    print(top_flows[['Exporter', 'Importer', 'Total Value']].to_string(index=False))\n",
    "\n",
    "except (IndexError, TypeError):\n",
    "    print(\"Could not find country code for 'China' to analyze trade flows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Q1c. Improve Display Formatting ---\n",
    "# Set pandas display options to make tables wider and prevent messy wrapping.\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "\n",
    "\n",
    "# --- 1. Setup and Data Loading ---\n",
    "\n",
    "# Define the base path to your raw data directory\n",
    "base_path = '/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw'\n",
    "trade_data_path = os.path.join(base_path, 'trade_data')\n",
    "\n",
    "# A dictionary to hold the loaded dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# List of all necessary files\n",
    "files_to_load = [\n",
    "    'baci_hs12_y2016_v202001.csv',\n",
    "    'baci_hs12_y2017_v202001.csv',\n",
    "    'baci_hs12_y2018_v202001.csv',\n",
    "    'country_codes_v202001.csv',\n",
    "    'product_codes_hs12_v202001.csv'\n",
    "]\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "for file in files_to_load:\n",
    "    file_path = os.path.join(trade_data_path, file)\n",
    "    df_name = file.split('.')[0]\n",
    "    try:\n",
    "        dataframes[df_name] = pd.read_csv(file_path, on_bad_lines='skip', encoding='latin1')\n",
    "        print(f\"- Successfully loaded {file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"- Error: File not found at {file_path}\")\n",
    "        exit()\n",
    "\n",
    "# Combine the yearly trade data\n",
    "baci_dfs = [df for name, df in dataframes.items() if 'baci_hs12_y' in name]\n",
    "df_trade_combined = pd.concat(baci_dfs, ignore_index=True)\n",
    "print(\"\\nCombined 2016-2018 trade data successfully.\")\n",
    "\n",
    "# Prepare code-to-name mapping tables\n",
    "df_country_codes = dataframes.get('country_codes_v202001')\n",
    "df_product_codes = dataframes.get('product_codes_hs12_v202001')\n",
    "\n",
    "if df_country_codes is None or df_product_codes is None:\n",
    "    print(\"Error: Code description files could not be loaded.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Calculate Top 10 Export Products (with Clean Formatting) ---\n",
    "\n",
    "print(\"\\n\\n--- Top 10 Export Products by Value (2016-2018) ---\")\n",
    "\n",
    "def get_top_10_exports(country_name, country_codes_df, trade_df, product_codes_df):\n",
    "    \"\"\"Calculates and prints the top 10 export products with clean formatting.\"\"\"\n",
    "    try:\n",
    "        country_code = int(country_codes_df[country_codes_df['country_name_full'].str.contains(country_name, na=False)].iloc[0]['country_code'])\n",
    "    except (IndexError, TypeError):\n",
    "        print(f\"\\nCould not find country code for '{country_name}'.\")\n",
    "        return\n",
    "\n",
    "    exports_df = trade_df[trade_df['i'] == country_code]\n",
    "    top_products = exports_df.groupby('k')['v'].sum().reset_index()\n",
    "    top_10 = top_products.sort_values(by='v', ascending=False).head(10)\n",
    "    \n",
    "    top_10_with_names = pd.merge(top_10, product_codes_df, left_on='k', right_on='code', how='left')\n",
    "    \n",
    "    # FORMATTING FIX: Truncate long descriptions for cleaner output\n",
    "    top_10_with_names['description'] = top_10_with_names['description'].str.slice(0, 75) + '...'\n",
    "    \n",
    "    print(f\"\\nTop 10 Exports for {country_name}:\")\n",
    "    top_10_with_names['v_formatted'] = top_10_with_names['v'].apply(lambda x: f\"${x:,.0f}K\")\n",
    "    \n",
    "    # Rename columns for final print\n",
    "    final_df = top_10_with_names[['description', 'v_formatted']].rename(\n",
    "        columns={'description': 'Product Description', 'v_formatted': 'Total Export Value'}\n",
    "    )\n",
    "    print(final_df.to_string(index=False))\n",
    "\n",
    "# Run the analysis for the three countries\n",
    "get_top_10_exports(\"China\", df_country_codes, df_trade_combined, df_product_codes)\n",
    "get_top_10_exports(\"Japan\", df_country_codes, df_trade_combined, df_product_codes)\n",
    "get_top_10_exports(\"United States of America\", df_country_codes, df_trade_combined, df_product_codes)\n",
    "\n",
    "\n",
    "# --- 3. Calculate Top 10 Globally Traded Goods (with Clean Formatting) ---\n",
    "\n",
    "print(\"\\n\\n--- Top 10 Globally Traded Goods (2016-2018) ---\")\n",
    "\n",
    "global_product_trade = df_trade_combined.groupby('k').agg(\n",
    "    total_value=('v', 'sum'),\n",
    "    total_quantity=('q', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Top 10 by Value\n",
    "top_10_value = global_product_trade.sort_values(by='total_value', ascending=False).head(10)\n",
    "top_10_value_named = pd.merge(top_10_value, df_product_codes, left_on='k', right_on='code', how='left')\n",
    "# FORMATTING FIX\n",
    "top_10_value_named['description'] = top_10_value_named['description'].str.slice(0, 75) + '...'\n",
    "top_10_value_named['value_formatted'] = top_10_value_named['total_value'].apply(lambda x: f\"${x:,.0f}K\")\n",
    "print(\"\\nTop 10 Goods with Highest Global Trade Volume by VALUE:\")\n",
    "print(top_10_value_named[['description', 'value_formatted']].rename(columns={'description': 'Product Description', 'value_formatted': 'Total Trade Value'}).to_string(index=False))\n",
    "\n",
    "# Top 10 by Quantity\n",
    "top_10_quantity = global_product_trade.sort_values(by='total_quantity', ascending=False).head(10)\n",
    "top_10_quantity_named = pd.merge(top_10_quantity, df_product_codes, left_on='k', right_on='code', how='left')\n",
    "# FORMATTING FIX\n",
    "top_10_quantity_named['description'] = top_10_quantity_named['description'].str.slice(0, 75) + '...'\n",
    "top_10_quantity_named['quantity_formatted'] = top_10_quantity_named['total_quantity'].apply(lambda x: f\"{x:,.0f} Metric Tons\")\n",
    "print(\"\\nTop 10 Goods with Highest Global Trade Volume by QUANTITY:\")\n",
    "print(top_10_quantity_named[['description', 'quantity_formatted']].rename(columns={'description': 'Product Description', 'quantity_formatted': 'Total Trade Quantity'}).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Q1d. Setup and Configuration ---\n",
    "# Set pandas display options for cleaner output and plot style.\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "# --- 1. Load All Necessary Data ---\n",
    "print(\"--- Loading Data ---\")\n",
    "base_path = '/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw'\n",
    "trade_data_path = os.path.join(base_path, 'trade_data')\n",
    "shapefile_path = os.path.join(base_path, 'countries_shapefile', 'cn_primary_countries.shp')\n",
    "\n",
    "# Load shapefile\n",
    "try:\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    print(\"- Successfully loaded countries shapefile.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading shapefile: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Load trade and country code data\n",
    "dataframes = {}\n",
    "files_to_load = [\n",
    "    'baci_hs12_y2016_v202001.csv', 'baci_hs12_y2017_v202001.csv', 'baci_hs12_y2018_v202001.csv',\n",
    "    'country_codes_v202001.csv'\n",
    "]\n",
    "for file in files_to_load:\n",
    "    file_path = os.path.join(trade_data_path, file)\n",
    "    try:\n",
    "        dataframes[file.split('.')[0]] = pd.read_csv(file_path, encoding='latin1')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        exit()\n",
    "print(\"- Successfully loaded all trade and code data.\")\n",
    "\n",
    "# Combine trade data\n",
    "baci_dfs = [df for name, df in dataframes.items() if 'baci_hs12_y' in name]\n",
    "df_trade_combined = pd.concat(baci_dfs, ignore_index=True)\n",
    "df_country_codes = dataframes.get('country_codes_v202001')\n",
    "\n",
    "\n",
    "# --- 2. Calculate Geographic Distances from China ---\n",
    "print(\"\\n--- Calculating Geographic Distances ---\")\n",
    "\n",
    "# The correct column for country names is 'name' based on your output.\n",
    "country_name_column = 'name' \n",
    "\n",
    "gdf_proj = gdf.to_crs(epsg=8857) # Reproject for accurate distance in meters\n",
    "gdf_proj['centroid'] = gdf_proj.geometry.centroid\n",
    "\n",
    "try:\n",
    "    china_centroid = gdf_proj[gdf_proj[country_name_column] == 'China'].centroid.iloc[0]\n",
    "except IndexError:\n",
    "    print(f\"FATAL ERROR: Could not find 'China' in the shapefile's '{country_name_column}' column.\")\n",
    "    exit()\n",
    "\n",
    "# Calculate distance in kilometers\n",
    "gdf['distance_to_china_km'] = gdf_proj.centroid.apply(lambda p: china_centroid.distance(p) / 1000)\n",
    "print(f\"- Calculated distances from China's centroid to {len(gdf)} other countries.\")\n",
    "\n",
    "df_distances = gdf[[country_name_column, 'distance_to_china_km']].rename(columns={country_name_column: 'country_name'})\n",
    "\n",
    "\n",
    "# --- 3. Calculate China's Export Volume ---\n",
    "print(\"\\n--- Calculating China's Export Volumes ---\")\n",
    "\n",
    "try:\n",
    "    china_code = int(df_country_codes[df_country_codes['country_name_full'] == 'China'].iloc[0]['country_code'])\n",
    "except (IndexError, TypeError):\n",
    "    print(\"FATAL ERROR: Could not find country code for 'China' in the country codes file.\")\n",
    "    exit()\n",
    "\n",
    "china_exports = df_trade_combined[df_trade_combined['i'] == china_code]\n",
    "export_volumes = china_exports.groupby('j').agg(\n",
    "    total_export_value=('v', 'sum'),\n",
    "    total_export_quantity=('q', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "export_volumes = pd.merge(export_volumes, df_country_codes, left_on='j', right_on='country_code', how='left')\n",
    "df_exports = export_volumes[['country_name_full', 'total_export_value', 'total_export_quantity']]\n",
    "df_exports = df_exports.rename(columns={'country_name_full': 'country_name'})\n",
    "print(f\"- Aggregated export data for {len(df_exports)} partner countries.\")\n",
    "\n",
    "# --- 4. Merge Distance and Trade Data ---\n",
    "print(\"\\n--- Merging Datasets for Plotting ---\")\n",
    "# Before merging, we must handle potential name mismatches between the two datasets\n",
    "# For example: 'United States of America' (trade file) vs. 'United States' (shapefile)\n",
    "name_corrections = {\n",
    "    'United States of America': 'United States',\n",
    "    'Republic of Korea': 'South Korea',\n",
    "    'Viet Nam': 'Vietnam'\n",
    "}\n",
    "df_exports['country_name'] = df_exports['country_name'].replace(name_corrections)\n",
    "\n",
    "# Now, merge the distance data with the export data\n",
    "df_final = pd.merge(df_distances, df_exports, on='country_name', how='inner')\n",
    "print(f\"- Successfully merged data. Found {len(df_final)} countries with both distance and trade data.\")\n",
    "\n",
    "if len(df_final) == 0:\n",
    "    print(\"WARNING: The merge resulted in an empty DataFrame. This is caused by country name mismatches.\")\n",
    "\n",
    "\n",
    "# --- 5. Create and Display Scatterplots ---\n",
    "print(\"\\n--- Generating Scatterplots ---\")\n",
    "\n",
    "if not df_final.empty:\n",
    "    plot_data = df_final[(df_final['total_export_value'] > 0) & (df_final['total_export_quantity'] > 0)].copy()\n",
    "    plot_data['log_value'] = np.log(plot_data['total_export_value'])\n",
    "    plot_data['log_quantity'] = np.log(plot_data['total_export_quantity'])\n",
    "\n",
    "    # Plot 1: Distance vs. Log Export Value\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.regplot(data=plot_data, x='distance_to_china_km', y='log_value',\n",
    "                scatter_kws={'alpha':0.6, 's':20}, line_kws={'color':'red', 'linestyle':'--'})\n",
    "    plt.title('Distance vs. Log of Export Value from China (2016-2018)', fontsize=16, pad=15)\n",
    "    plt.xlabel('Distance from China (km)', fontsize=12)\n",
    "    plt.ylabel('Natural Log of Total Export Value (in thousands USD)', fontsize=12)\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 2: Distance vs. Log Export Quantity\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.regplot(data=plot_data, x='distance_to_china_km', y='log_quantity',\n",
    "                scatter_kws={'alpha':0.6, 's':20, 'color':'green'}, line_kws={'color':'red', 'linestyle':'--'})\n",
    "    plt.title('Distance vs. Log of Export Quantity from China (2016-2018)', fontsize=16, pad=15)\n",
    "    plt.xlabel('Distance from China (km)', fontsize=12)\n",
    "    plt.ylabel('Natural Log of Total Export Quantity (in Metric Tons)', fontsize=12)\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nSkipping plot generation because the merged DataFrame is empty.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5020_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
