{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807072f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup -- preview\n",
    "# Import necessary libraries and define the base path for the data files.\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161ce935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path to your raw data directory\n",
    "# IMPORTANT: Make sure this path is correct for your system.\n",
    "base_path = '/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286cee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading GDP Data ---\n",
      "Successfully loaded GDP data.\n",
      "First 5 rows of GDP data:\n",
      "                  Country Name Country Code     Indicator Name  \\\n",
      "0                        Aruba          ABW  GDP (current US$)   \n",
      "1  Africa Eastern and Southern          AFE  GDP (current US$)   \n",
      "2                  Afghanistan          AFG  GDP (current US$)   \n",
      "3   Africa Western and Central          AFW  GDP (current US$)   \n",
      "4                       Angola          AGO  GDP (current US$)   \n",
      "\n",
      "   Indicator Code          1960          1961          1962          1963  \\\n",
      "0  NY.GDP.MKTP.CD           NaN           NaN           NaN           NaN   \n",
      "1  NY.GDP.MKTP.CD  2.420993e+10  2.496326e+10  2.707802e+10  3.177483e+10   \n",
      "2  NY.GDP.MKTP.CD           NaN           NaN           NaN           NaN   \n",
      "3  NY.GDP.MKTP.CD  1.190511e+10  1.270803e+10  1.363092e+10  1.446926e+10   \n",
      "4  NY.GDP.MKTP.CD           NaN           NaN           NaN           NaN   \n",
      "\n",
      "           1964          1965  ...          2016          2017          2018  \\\n",
      "0           NaN           NaN  ...  2.983635e+09  3.092429e+09  3.276184e+09   \n",
      "1  3.028492e+10  3.381219e+10  ...  8.289612e+11  9.730251e+11  1.012291e+12   \n",
      "2           NaN           NaN  ...  1.811657e+10  1.875346e+10  1.805322e+10   \n",
      "3  1.580394e+10  1.692124e+10  ...  7.000282e+11  6.940513e+11  7.778404e+11   \n",
      "4           NaN           NaN  ...  5.276162e+10  7.369015e+10  7.945069e+10   \n",
      "\n",
      "           2019          2020          2021          2022          2023  \\\n",
      "0  3.395799e+09  2.481857e+09  2.929447e+09  3.279344e+09  3.648573e+09   \n",
      "1  1.009747e+12  9.334072e+11  1.085605e+12  1.191639e+12  1.133818e+12   \n",
      "2  1.879944e+10  1.995593e+10  1.426000e+10  1.449724e+10  1.715223e+10   \n",
      "3  8.332889e+11  7.972952e+11  8.581145e+11  8.936399e+11  8.147285e+11   \n",
      "4  7.089796e+10  4.850156e+10  6.650513e+10  1.043997e+11  8.487516e+10   \n",
      "\n",
      "           2024  Unnamed: 69  \n",
      "0           NaN          NaN  \n",
      "1  1.205974e+12          NaN  \n",
      "2           NaN          NaN  \n",
      "3  6.700257e+11          NaN  \n",
      "4  8.039694e+10          NaN  \n",
      "\n",
      "[5 rows x 70 columns]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Load GDP Data\n",
    "# Load the world GDP data from api_ny_gdp_mktp_cd_ds2.csv.\n",
    "print(\"--- Loading GDP Data ---\")\n",
    "gdp_file_path = os.path.join(base_path, 'api_ny_gdp_mktp_cd_ds2.csv')\n",
    "\n",
    "try:\n",
    "    # We skip the first 4 rows which contain metadata, not the actual data.\n",
    "    df_gdp = pd.read_csv(gdp_file_path, skiprows=4)\n",
    "    print(\"Successfully loaded GDP data.\")\n",
    "    print(\"First 5 rows of GDP data:\")\n",
    "    print(df_gdp.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: GDP file not found at {gdp_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eecb887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Countries Shapefile ---\n",
      "Successfully loaded countries shapefile.\n",
      "First 5 rows of the shapefile data:\n",
      "  ADM0_A3  abbrev continent                    formal_nam iso_a2 iso_a3  \\\n",
      "0     AFG    Afg.      Asia  Islamic State of Afghanistan     AF    AFG   \n",
      "1     AGO    Ang.    Africa   People's Republic of Angola     AO    AGO   \n",
      "2     ALB    Alb.    Europe           Republic of Albania     AL    ALB   \n",
      "3     AND    And.    Europe       Principality of Andorra     AD    AND   \n",
      "4     ARE  U.A.E.      Asia          United Arab Emirates     AE    ARE   \n",
      "\n",
      "   iso_n3                   iso_short                  name  \\\n",
      "0       4                 Afghanistan           Afghanistan   \n",
      "1      24                      Angola                Angola   \n",
      "2       8                     Albania               Albania   \n",
      "3      20                     Andorra               Andorra   \n",
      "4     784  United Arab Emirates (the)  United Arab Emirates   \n",
      "\n",
      "              name_sort  ...                      un_fr  un_n3 un_region  \\\n",
      "0           Afghanistan  ...   Afghanistan (l') [masc.]      4      Asia   \n",
      "1                Angola  ...        Angola (l') [masc.]     24    Africa   \n",
      "2               Albania  ...        Albanie (l') [fém.]      8    Europe   \n",
      "3               Andorra  ...        Andorre (l') [fém.]     20    Europe   \n",
      "4  United Arab Emirates  ...  Émirats arabes unis (les)    784      Asia   \n",
      "\n",
      "                           un_ru       un_subregi     un_zh wb_a2 wb_a3  \\\n",
      "0                     Афганистан    Southern Asia       阿富汗    AF   AFG   \n",
      "1                         Ангола    Middle Africa       安哥拉    AO   AGO   \n",
      "2                        Албания  Southern Europe     阿尔巴尼亚    AL   ALB   \n",
      "3                        Андорра  Southern Europe       安道尔    AD   ADO   \n",
      "4  Объединенные Арабские Эмираты     Western Asia  阿拉伯联合酋长国    AE   ARE   \n",
      "\n",
      "                    wb_region  \\\n",
      "0                  South Asia   \n",
      "1          Sub-Saharan Africa   \n",
      "2       Europe & Central Asia   \n",
      "3       Europe & Central Asia   \n",
      "4  Middle East & North Africa   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((74.89231 37.23111, 74.81314 37.21543...  \n",
      "1  MULTIPOLYGON (((11.73752 -16.69258, 11.73851 -...  \n",
      "2  POLYGON ((20.06496 42.54676, 20.08563 42.53001...  \n",
      "3  POLYGON ((1.70701 42.50278, 1.6975 42.49446, 1...  \n",
      "4  MULTIPOLYGON (((53.86305 24.23469, 53.8886 24....  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Load Countries Shapefile\n",
    "# Load the country boundaries from the shapefile.\n",
    "print(\"--- Loading Countries Shapefile ---\")\n",
    "shapefile_path = os.path.join(base_path, 'countries_shapefile', 'cn_primary_countries.shp')\n",
    "\n",
    "try:\n",
    "    gdf_countries = gpd.read_file(shapefile_path)\n",
    "    print(\"Successfully loaded countries shapefile.\")\n",
    "    print(\"First 5 rows of the shapefile data:\")\n",
    "    print(gdf_countries.head())\n",
    "except Exception as e:\n",
    "    # Using a general exception as geopandas can have various backend errors\n",
    "    print(f\"Error loading shapefile: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c34f0da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Trade Data ---\n",
      "- Successfully loaded baci_hs12_y2016_v202001.csv\n",
      "- Successfully loaded baci_hs12_y2017_v202001.csv\n",
      "- Successfully loaded baci_hs12_y2018_v202001.csv\n",
      "- An error occurred while loading country_codes_v202001.csv: 'utf-8' codec can't decode byte 0xf4 in position 4141: invalid continuation byte\n",
      "- Successfully loaded product_codes_hs12_v202001.csv\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Load Trade Data\n",
    "# Load the various trade-related datasets from the `trade_data` directory.\n",
    "print(\"--- Loading Trade Data ---\")\n",
    "trade_data_path = os.path.join(base_path, 'trade_data')\n",
    "trade_files = [\n",
    "    'baci_hs12_y2016_v202001.csv',\n",
    "    'baci_hs12_y2017_v202001.csv',\n",
    "    'baci_hs12_y2018_v202001.csv',\n",
    "    'country_codes_v202001.csv',\n",
    "    'product_codes_hs12_v202001.csv'\n",
    "]\n",
    "\n",
    "# A dictionary to hold all the loaded trade dataframes\n",
    "trade_dataframes = {}\n",
    "\n",
    "for file in trade_files:\n",
    "    file_path = os.path.join(trade_data_path, file)\n",
    "    # Use a clean name for the dictionary key (e.g., 'baci_hs12_y2016_v202001')\n",
    "    df_name = file.split('.')[0]\n",
    "    try:\n",
    "        trade_dataframes[df_name] = pd.read_csv(file_path)\n",
    "        print(f\"- Successfully loaded {file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"- Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"- An error occurred while loading {file}: {e}\")\n",
    "\n",
    "# You can now access each dataframe from the dictionary, for example:\n",
    "if 'country_codes_v202001' in trade_dataframes:\n",
    "    print(\"\\nExample: First 5 rows of country_codes_v202001.csv:\")\n",
    "    print(trade_dataframes['country_codes_v202001'].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3bffdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Combining yearly BACI trade data ---\n",
      "Successfully combined yearly BACI trade data into a single DataFrame.\n",
      "Total rows in combined data: 24025656\n",
      "\n",
      "First 5 rows of combined BACI data:\n",
      "      t  i   j       k           v        q\n",
      "0  2016  4  12   80132   26.313000    3.000\n",
      "1  2016  4  12  130190    1.507000    0.585\n",
      "2  2016  4  12  370239    1.121000    0.003\n",
      "3  2016  4  12  970600   17.236000    0.019\n",
      "4  2016  4  24  480300  315.120626  186.534\n",
      "\n",
      "Last 5 rows of combined BACI data:\n",
      "             t    i    j       k           v          q\n",
      "24025651  2018  894  842  960190   76.858000   5.075000\n",
      "24025652  2018  894  842  970190    4.519000   0.214000\n",
      "24025653  2018  894  842  970500   55.777523  13.648432\n",
      "24025654  2018  894  854  100510    3.481420   0.411995\n",
      "24025655  2018  894  858  240120  124.686453  19.800000\n"
     ]
    }
   ],
   "source": [
    "# 5. Optional: Combine yearly trade data\n",
    "# If the yearly BACI trade files have the same columns, we can combine them.\n",
    "print(\"--- Combining yearly BACI trade data ---\")\n",
    "baci_trade_dfs_to_combine = []\n",
    "for key, df in trade_dataframes.items():\n",
    "    if 'baci_hs12_y' in key:\n",
    "        baci_trade_dfs_to_combine.append(df)\n",
    "\n",
    "if baci_trade_dfs_to_combine:\n",
    "    df_baci_combined = pd.concat(baci_trade_dfs_to_combine, ignore_index=True)\n",
    "    print(\"Successfully combined yearly BACI trade data into a single DataFrame.\")\n",
    "    print(f\"Total rows in combined data: {len(df_baci_combined)}\")\n",
    "    print(\"\\nFirst 5 rows of combined BACI data:\")\n",
    "    print(df_baci_combined.head())\n",
    "    print(\"\\nLast 5 rows of combined BACI data:\")\n",
    "    print(df_baci_combined.tail())\n",
    "else:\n",
    "    print(\"No BACI dataframes were found to combine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39cf1777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "- Successfully loaded baci_hs12_y2016_v202001.csv\n",
      "- Successfully loaded baci_hs12_y2017_v202001.csv\n",
      "- Successfully loaded baci_hs12_y2018_v202001.csv\n",
      "- Successfully loaded country_codes_v202001.csv\n",
      "\n",
      "Combined 2016-2018 trade data successfully.\n",
      "\n",
      "\n",
      "--- Descriptive Statistics: Trading Partners (2016-2018) ---\n",
      "\n",
      "Top 10 Countries with the Most Trading Partners:\n",
      "      country_name  partner_count\n",
      "           Germany            220\n",
      "       Netherlands            220\n",
      "    France, Monaco            220\n",
      "             Spain            220\n",
      "            Poland            220\n",
      "             Italy            220\n",
      "          Thailand            220\n",
      "           Czechia            219\n",
      "    United Kingdom            219\n",
      "Belgium-Luxembourg            219\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Bottom 10 Countries with the Fewest Trading Partners:\n",
      "                      country_name  partner_count\n",
      "     Federated State of Micronesia             56\n",
      "         Wallis and Futuna Islands             54\n",
      "French South Antarctic Territories             52\n",
      "                   Norfolk Islands             51\n",
      "                 Christmas Islands             50\n",
      "        Saint Maarten (Dutch part)             50\n",
      "                  Saint Barthélemy             46\n",
      "         Saint Pierre and Miquelon             43\n",
      " Bonaire, Saint Eustatius and Saba             36\n",
      "              Netherlands Antilles              1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Q1a. Setup and Data Loading ---\n",
    "# This version adds the encoding='latin1' parameter to handle the file encoding error.\n",
    "\n",
    "# Define the base path to your raw data directory\n",
    "base_path = '/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw'\n",
    "trade_data_path = os.path.join(base_path, 'trade_data')\n",
    "\n",
    "# A dictionary to hold the loaded dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# List of files to load\n",
    "files_to_load = [\n",
    "    'baci_hs12_y2016_v202001.csv',\n",
    "    'baci_hs12_y2017_v202001.csv',\n",
    "    'baci_hs12_y2018_v202001.csv',\n",
    "    'country_codes_v202001.csv'\n",
    "]\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "for file in files_to_load:\n",
    "    file_path = os.path.join(trade_data_path, file)\n",
    "    df_name = file.split('.')[0]\n",
    "    try:\n",
    "        # THE FIX IS HERE: Added encoding='latin1' to handle non-UTF-8 characters\n",
    "        dataframes[df_name] = pd.read_csv(file_path, on_bad_lines='skip', encoding='latin1')\n",
    "        print(f\"- Successfully loaded {file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"- Error: File not found at {file_path}\")\n",
    "        exit()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while loading {file}: {e}\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "# Combine the three years of trade data into one DataFrame\n",
    "baci_dfs = [df for name, df in dataframes.items() if 'baci_hs12_y' in name]\n",
    "if not baci_dfs:\n",
    "    print(\"Error: No BACI trade data files were loaded. Cannot proceed.\")\n",
    "    exit()\n",
    "\n",
    "df_trade_combined = pd.concat(baci_dfs, ignore_index=True)\n",
    "print(\"\\nCombined 2016-2018 trade data successfully.\\n\")\n",
    "\n",
    "# Load country codes for mapping codes to names\n",
    "df_country_codes = dataframes.get('country_codes_v202001')\n",
    "if df_country_codes is None:\n",
    "    print(\"Error: country_codes_v202001.csv could not be loaded. Cannot map country names.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Calculate Trading Partners for Each Country ---\n",
    "# The logic here remains the same as before.\n",
    "\n",
    "# Get a list of all unique country codes present in the trade data\n",
    "all_country_codes = pd.unique(df_trade_combined[['i', 'j']].values.ravel('K'))\n",
    "\n",
    "partner_counts = {}\n",
    "\n",
    "for code in all_country_codes:\n",
    "    # Find all countries this country exported to\n",
    "    exports_to = set(df_trade_combined[df_trade_combined['i'] == code]['j'])\n",
    "    \n",
    "    # Find all countries this country imported from\n",
    "    imports_from = set(df_trade_combined[df_trade_combined['j'] == code]['i'])\n",
    "    \n",
    "    # The set of unique partners is the union of the two sets\n",
    "    unique_partners = exports_to.union(imports_from)\n",
    "    \n",
    "    # Count the number of partners and store it\n",
    "    partner_counts[code] = len(unique_partners)\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame for easier sorting and merging\n",
    "df_partner_counts = pd.DataFrame(list(partner_counts.items()), columns=['country_code', 'partner_count'])\n",
    "\n",
    "# Merge with the country names for a readable output\n",
    "if 'country_name_full' in df_country_codes.columns and 'country_code' in df_country_codes.columns:\n",
    "    df_results = pd.merge(df_partner_counts, df_country_codes[['country_code', 'country_name_full']], on='country_code', how='left')\n",
    "    df_results = df_results.sort_values(by='partner_count', ascending=False).reset_index(drop=True)\n",
    "    df_results = df_results.rename(columns={'country_name_full': 'country_name'})\n",
    "else:\n",
    "    print(\"Country code file does not have expected columns 'country_code' and 'country_name_full'. Cannot display full names.\")\n",
    "    df_results = df_partner_counts.sort_values(by='partner_count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- 3. Display Descriptive Statistics ---\n",
    "\n",
    "print(\"\\n--- Descriptive Statistics: Trading Partners (2016-2018) ---\\n\")\n",
    "\n",
    "# Top 10 Countries with the Most Trading Partners\n",
    "print(\"Top 10 Countries with the Most Trading Partners:\")\n",
    "# Fill potential missing names with the code for robustness\n",
    "df_results['country_name'] = df_results['country_name'].fillna('Unknown')\n",
    "top_10 = df_results.head(10)\n",
    "print(top_10[['country_name', 'partner_count']].to_string(index=False))\n",
    "\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "\n",
    "# Bottom 10 Countries with the Fewest Trading Partners\n",
    "print(\"Bottom 10 Countries with the Fewest Trading Partners:\")\n",
    "bottom_10 = df_results[df_results['partner_count'] > 0].tail(10)\n",
    "print(bottom_10[['country_name', 'partner_count']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc43a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "- Successfully loaded baci_hs12_y2016_v202001.csv\n",
      "- Successfully loaded baci_hs12_y2017_v202001.csv\n",
      "- Successfully loaded baci_hs12_y2018_v202001.csv\n",
      "- Successfully loaded country_codes_v202001.csv\n",
      "- Successfully loaded product_codes_hs12_v202001.csv\n",
      "\n",
      "Combined 2016-2018 trade data successfully.\n",
      "\n",
      "--- Overall Trade Volume Description (2016-2018) ---\n",
      "Total Global Trade Value (sum of all flows): $50,225,134,798 thousand USD\n",
      "\n",
      "Descriptive Statistics for Trade Value ('v') per flow:\n",
      "   Count: 24,025,656.00\n",
      "    Mean: 2,090.48\n",
      "     Std: 66,877.52\n",
      "     Min: 1.00\n",
      "     25%: 5.94\n",
      "     50%: 30.02\n",
      "     75%: 202.04\n",
      "     Max: 61,895,755.21\n",
      "\n",
      "\n",
      "--- Top 10 Trading Partners by Total Value (2016-2018) ---\n",
      "\n",
      "Top 10 Partners for China:\n",
      "                               Partner Country Total Trade Value\n",
      "        USA, Puerto Rico and US Virgin Islands   $1,802,824,456K\n",
      "                                         Japan     $870,648,429K\n",
      "China, Hong Kong Special Administrative Region     $820,063,612K\n",
      "                             Republic of Korea     $729,437,845K\n",
      "                                       Germany     $605,461,447K\n",
      "           Other Asia, not elsewhere specified     $417,416,441K\n",
      "                                     Australia     $398,878,581K\n",
      "                                      Viet Nam     $303,226,069K\n",
      "                            Russian Federation     $262,801,888K\n",
      "                                United Kingdom     $246,128,453K\n",
      "Could not find country code for 'United States of America'.\n",
      "\n",
      "\n",
      "--- Five Highest-Value China Trade Flows (2016-2018) ---\n",
      "Top 5 individual trade flows involving China (sum of all products and years):\n",
      "         Exporter                                       Importer     Total Value\n",
      "            China         USA, Puerto Rico and US Virgin Islands $1,429,004,089K\n",
      "            China China, Hong Kong Special Administrative Region   $764,135,504K\n",
      "            China                                          Japan   $465,442,395K\n",
      "Republic of Korea                                          China   $439,475,542K\n",
      "            Japan                                          China   $405,206,034K\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Q1b. Setup and Data Loading (Including Product Codes) ---\n",
    "\n",
    "# Define the base path to your raw data directory\n",
    "base_path = '/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw'\n",
    "trade_data_path = os.path.join(base_path, 'trade_data')\n",
    "\n",
    "# A dictionary to hold the loaded dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# List of all necessary files\n",
    "files_to_load = [\n",
    "    'baci_hs12_y2016_v202001.csv',\n",
    "    'baci_hs12_y2017_v202001.csv',\n",
    "    'baci_hs12_y2018_v202001.csv',\n",
    "    'country_codes_v202001.csv',\n",
    "    'product_codes_hs12_v202001.csv'\n",
    "]\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "for file in files_to_load:\n",
    "    file_path = os.path.join(trade_data_path, file)\n",
    "    df_name = file.split('.')[0]\n",
    "    try:\n",
    "        # Use encoding='latin1' to prevent UnicodeDecodeError\n",
    "        dataframes[df_name] = pd.read_csv(file_path, on_bad_lines='skip', encoding='latin1')\n",
    "        print(f\"- Successfully loaded {file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"- Error: File not found at {file_path}\")\n",
    "        exit()\n",
    "\n",
    "# Combine the yearly trade data\n",
    "baci_dfs = [df for name, df in dataframes.items() if 'baci_hs12_y' in name]\n",
    "if not baci_dfs:\n",
    "    print(\"Error: No BACI trade data files were loaded. Cannot proceed.\")\n",
    "    exit()\n",
    "df_trade_combined = pd.concat(baci_dfs, ignore_index=True)\n",
    "print(\"\\nCombined 2016-2018 trade data successfully.\")\n",
    "\n",
    "# Prepare code-to-name mapping tables\n",
    "df_country_codes = dataframes.get('country_codes_v202001')\n",
    "df_product_codes = dataframes.get('product_codes_hs12_v202001')\n",
    "\n",
    "if df_country_codes is None or df_product_codes is None:\n",
    "    print(\"Error: Code description files could not be loaded.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Describe Overall Trade Volume ---\n",
    "\n",
    "print(\"\\n--- Overall Trade Volume Description (2016-2018) ---\")\n",
    "# The trade value 'v' is in thousands of US dollars.\n",
    "total_trade_value = df_trade_combined['v'].sum()\n",
    "print(f\"Total Global Trade Value (sum of all flows): ${total_trade_value:,.0f} thousand USD\")\n",
    "\n",
    "print(\"\\nDescriptive Statistics for Trade Value ('v') per flow:\")\n",
    "# Using describe() to get a statistical summary\n",
    "description = df_trade_combined['v'].describe()\n",
    "# Format the output for readability\n",
    "for idx, val in description.items():\n",
    "    print(f\"{idx.capitalize():>8}: {val:,.2f}\")\n",
    "\n",
    "\n",
    "# --- 3. Identify Top 10 Partners for China and the USA ---\n",
    "\n",
    "print(\"\\n\\n--- Top 10 Trading Partners by Total Value (2016-2018) ---\")\n",
    "\n",
    "def get_top_10_partners(country_name_str, country_codes_df, trade_df):\n",
    "    \"\"\"Calculates and prints the top 10 trading partners for a given country.\"\"\"\n",
    "    try:\n",
    "        country_code = int(country_codes_df[country_codes_df['country_name_full'].str.contains(country_name_str, na=False)].iloc[0]['country_code'])\n",
    "    except (IndexError, TypeError):\n",
    "        print(f\"Could not find country code for '{country_name_str}'.\")\n",
    "        return\n",
    "\n",
    "    # Filter for all trade involving the country (as exporter 'i' or importer 'j')\n",
    "    country_trade_df = trade_df[(trade_df['i'] == country_code) | (trade_df['j'] == country_code)].copy()\n",
    "    \n",
    "    # Determine the partner code for each transaction\n",
    "    country_trade_df['partner_code'] = country_trade_df.apply(\n",
    "        lambda row: row['j'] if row['i'] == country_code else row['i'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Group by partner and sum the trade value\n",
    "    partner_trade = country_trade_df.groupby('partner_code')['v'].sum().reset_index()\n",
    "    \n",
    "    # Merge with country names to get partner names\n",
    "    partner_trade = pd.merge(partner_trade, country_codes_df[['country_code', 'country_name_full']], left_on='partner_code', right_on='country_code', how='left')\n",
    "    \n",
    "    # Sort to find the top partners\n",
    "    top_10 = partner_trade.sort_values(by='v', ascending=False).head(10)\n",
    "    \n",
    "    print(f\"\\nTop 10 Partners for {country_name_str}:\")\n",
    "    top_10['v_formatted'] = top_10['v'].apply(lambda x: f\"${x:,.0f}K\")\n",
    "    print(top_10[['country_name_full', 'v_formatted']].rename(columns={'country_name_full': 'Partner Country', 'v_formatted': 'Total Trade Value'}).to_string(index=False))\n",
    "\n",
    "# Run the function for China and the United States\n",
    "get_top_10_partners(\"China\", df_country_codes, df_trade_combined)\n",
    "get_top_10_partners(\"United States of America\", df_country_codes, df_trade_combined)\n",
    "\n",
    "\n",
    "# --- 4. List the Five Highest-Value China Trade Flows ---\n",
    "\n",
    "print(\"\\n\\n--- Five Highest-Value China Trade Flows (2016-2018) ---\")\n",
    "\n",
    "try:\n",
    "    china_code = int(df_country_codes[df_country_codes['country_name_full'].str.contains(\"China\", na=False)].iloc[0]['country_code'])\n",
    "\n",
    "    # Filter for all trade involving China\n",
    "    china_trade_df = df_trade_combined[(df_trade_combined['i'] == china_code) | (df_trade_combined['j'] == china_code)]\n",
    "\n",
    "    # Group by the specific flow (exporter and importer) and sum the value\n",
    "    flow_values = china_trade_df.groupby(['i', 'j'])['v'].sum().reset_index()\n",
    "    \n",
    "    # Sort to find the highest-value flows\n",
    "    top_flows = flow_values.sort_values(by='v', ascending=False).head(5)\n",
    "\n",
    "    # Merge to get exporter names\n",
    "    top_flows = pd.merge(top_flows, df_country_codes[['country_code', 'country_name_full']], left_on='i', right_on='country_code', how='left')\n",
    "    top_flows = top_flows.rename(columns={'country_name_full': 'Exporter'})\n",
    "    \n",
    "    # Merge to get importer names\n",
    "    top_flows = pd.merge(top_flows, df_country_codes[['country_code', 'country_name_full']], left_on='j', right_on='country_code', how='left')\n",
    "    top_flows = top_flows.rename(columns={'country_name_full': 'Importer'})\n",
    "    \n",
    "    # Format for printing\n",
    "    top_flows['Total Value'] = top_flows['v'].apply(lambda x: f\"${x:,.0f}K\")\n",
    "\n",
    "    print(\"Top 5 individual trade flows involving China (sum of all products and years):\")\n",
    "    print(top_flows[['Exporter', 'Importer', 'Total Value']].to_string(index=False))\n",
    "\n",
    "except (IndexError, TypeError):\n",
    "    print(\"Could not find country code for 'China' to analyze trade flows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44332b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "- Error: File not found at /Users/leo/Desktop/CNGF5020/MINIPRO_2/raw/trade_data/baci_hs12_y2016_v202001.csv\n",
      "- Error: File not found at /Users/leo/Desktop/CNGF5020/MINIPRO_2/raw/trade_data/baci_hs12_y2017_v202001.csv\n",
      "- Error: File not found at /Users/leo/Desktop/CNGF5020/MINIPRO_2/raw/trade_data/baci_hs12_y2018_v202001.csv\n",
      "- Error: File not found at /Users/leo/Desktop/CNGF5020/MINIPRO_2/raw/trade_data/country_codes_v202001.csv\n",
      "- Error: File not found at /Users/leo/Desktop/CNGF5020/MINIPRO_2/raw/trade_data/product_codes_hs12_v202001.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Combine the yearly trade data\u001b[39;00m\n\u001b[32m     40\u001b[39m baci_dfs = [df \u001b[38;5;28;01mfor\u001b[39;00m name, df \u001b[38;5;129;01min\u001b[39;00m dataframes.items() \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mbaci_hs12_y\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name]\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m df_trade_combined = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaci_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCombined 2016-2018 trade data successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Prepare code-to-name mapping tables\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/5020_env/lib/python3.11/site-packages/pandas/core/reshape/concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/5020_env/lib/python3.11/site-packages/pandas/core/reshape/concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/5020_env/lib/python3.11/site-packages/pandas/core/reshape/concat.py:507\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    504\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    510\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Q1c. Improve Display Formatting ---\n",
    "# Set pandas display options to make tables wider and prevent messy wrapping.\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "\n",
    "\n",
    "# --- 1. Setup and Data Loading ---\n",
    "\n",
    "# Define the base path to your raw data directory\n",
    "base_path = '/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw'\n",
    "trade_data_path = os.path.join(base_path, 'trade_data')\n",
    "\n",
    "# A dictionary to hold the loaded dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# List of all necessary files\n",
    "files_to_load = [\n",
    "    'baci_hs12_y2016_v202001.csv',\n",
    "    'baci_hs12_y2017_v202001.csv',\n",
    "    'baci_hs12_y2018_v202001.csv',\n",
    "    'country_codes_v202001.csv',\n",
    "    'product_codes_hs12_v202001.csv'\n",
    "]\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "for file in files_to_load:\n",
    "    file_path = os.path.join(trade_data_path, file)\n",
    "    df_name = file.split('.')[0]\n",
    "    try:\n",
    "        dataframes[df_name] = pd.read_csv(file_path, on_bad_lines='skip', encoding='latin1')\n",
    "        print(f\"- Successfully loaded {file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"- Error: File not found at {file_path}\")\n",
    "        exit()\n",
    "\n",
    "# Combine the yearly trade data\n",
    "baci_dfs = [df for name, df in dataframes.items() if 'baci_hs12_y' in name]\n",
    "df_trade_combined = pd.concat(baci_dfs, ignore_index=True)\n",
    "print(\"\\nCombined 2016-2018 trade data successfully.\")\n",
    "\n",
    "# Prepare code-to-name mapping tables\n",
    "df_country_codes = dataframes.get('country_codes_v202001')\n",
    "df_product_codes = dataframes.get('product_codes_hs12_v202001')\n",
    "\n",
    "if df_country_codes is None or df_product_codes is None:\n",
    "    print(\"Error: Code description files could not be loaded.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Calculate Top 10 Export Products (with Clean Formatting) ---\n",
    "\n",
    "print(\"\\n\\n--- Top 10 Export Products by Value (2016-2018) ---\")\n",
    "\n",
    "def get_top_10_exports(country_name, country_codes_df, trade_df, product_codes_df):\n",
    "    \"\"\"Calculates and prints the top 10 export products with clean formatting.\"\"\"\n",
    "    try:\n",
    "        country_code = int(country_codes_df[country_codes_df['country_name_full'].str.contains(country_name, na=False)].iloc[0]['country_code'])\n",
    "    except (IndexError, TypeError):\n",
    "        print(f\"\\nCould not find country code for '{country_name}'.\")\n",
    "        return\n",
    "\n",
    "    exports_df = trade_df[trade_df['i'] == country_code]\n",
    "    top_products = exports_df.groupby('k')['v'].sum().reset_index()\n",
    "    top_10 = top_products.sort_values(by='v', ascending=False).head(10)\n",
    "    \n",
    "    top_10_with_names = pd.merge(top_10, product_codes_df, left_on='k', right_on='code', how='left')\n",
    "    \n",
    "    # FORMATTING FIX: Truncate long descriptions for cleaner output\n",
    "    top_10_with_names['description'] = top_10_with_names['description'].str.slice(0, 75) + '...'\n",
    "    \n",
    "    print(f\"\\nTop 10 Exports for {country_name}:\")\n",
    "    top_10_with_names['v_formatted'] = top_10_with_names['v'].apply(lambda x: f\"${x:,.0f}K\")\n",
    "    \n",
    "    # Rename columns for final print\n",
    "    final_df = top_10_with_names[['description', 'v_formatted']].rename(\n",
    "        columns={'description': 'Product Description', 'v_formatted': 'Total Export Value'}\n",
    "    )\n",
    "    print(final_df.to_string(index=False))\n",
    "\n",
    "# Run the analysis for the three countries\n",
    "get_top_10_exports(\"China\", df_country_codes, df_trade_combined, df_product_codes)\n",
    "get_top_10_exports(\"Japan\", df_country_codes, df_trade_combined, df_product_codes)\n",
    "get_top_10_exports(\"United States of America\", df_country_codes, df_trade_combined, df_product_codes)\n",
    "\n",
    "\n",
    "# --- 3. Calculate Top 10 Globally Traded Goods (with Clean Formatting) ---\n",
    "\n",
    "print(\"\\n\\n--- Top 10 Globally Traded Goods (2016-2018) ---\")\n",
    "\n",
    "global_product_trade = df_trade_combined.groupby('k').agg(\n",
    "    total_value=('v', 'sum'),\n",
    "    total_quantity=('q', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Top 10 by Value\n",
    "top_10_value = global_product_trade.sort_values(by='total_value', ascending=False).head(10)\n",
    "top_10_value_named = pd.merge(top_10_value, df_product_codes, left_on='k', right_on='code', how='left')\n",
    "# FORMATTING FIX\n",
    "top_10_value_named['description'] = top_10_value_named['description'].str.slice(0, 75) + '...'\n",
    "top_10_value_named['value_formatted'] = top_10_value_named['total_value'].apply(lambda x: f\"${x:,.0f}K\")\n",
    "print(\"\\nTop 10 Goods with Highest Global Trade Volume by VALUE:\")\n",
    "print(top_10_value_named[['description', 'value_formatted']].rename(columns={'description': 'Product Description', 'value_formatted': 'Total Trade Value'}).to_string(index=False))\n",
    "\n",
    "# Top 10 by Quantity\n",
    "top_10_quantity = global_product_trade.sort_values(by='total_quantity', ascending=False).head(10)\n",
    "top_10_quantity_named = pd.merge(top_10_quantity, df_product_codes, left_on='k', right_on='code', how='left')\n",
    "# FORMATTING FIX\n",
    "top_10_quantity_named['description'] = top_10_quantity_named['description'].str.slice(0, 75) + '...'\n",
    "top_10_quantity_named['quantity_formatted'] = top_10_quantity_named['total_quantity'].apply(lambda x: f\"{x:,.0f} Metric Tons\")\n",
    "print(\"\\nTop 10 Goods with Highest Global Trade Volume by QUANTITY:\")\n",
    "print(top_10_quantity_named[['description', 'quantity_formatted']].rename(columns={'description': 'Product Description', 'quantity_formatted': 'Total Trade Quantity'}).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d4811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5020_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
