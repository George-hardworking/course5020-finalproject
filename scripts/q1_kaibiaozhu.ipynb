{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9c6f17",
   "metadata": {},
   "source": [
    "# Q1 - 描述性分析（贸易数据）\n",
    "本笔记本完成：读取 `raw` 下的贸易与参考文件，生成近三年（2016-2018）的描述性统计，匹配产品与国家代码，计算中美的主要贸易伙伴，并基于国家形状文件计算中国重心与其它国家重心之间的距离并画出对数散点图。\n",
    "\n",
    "注：如果运行环境缺少包，下面的单元会尝试安装 `geopandas`、`pyproj` 和绘图所需库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60609b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project root: /Users/kaibiaozhu/Documents/GitHub/course5020-finalproject\n",
      "Using trade files: [PosixPath('/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw/trade_data/baci_hs12_y2016_v202001.csv'), PosixPath('/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw/trade_data/baci_HS12_y2017_v202001.csv'), PosixPath('/Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw/trade_data/baci_hs12_y2018_v202001.csv')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe43d70915f47548caf1cdedfd7d537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading trade CSVs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw/trade_data/baci_hs12_y2016_v202001.csv\n",
      "Reading /Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw/trade_data/baci_HS12_y2017_v202001.csv\n",
      "Reading /Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw/trade_data/baci_HS12_y2017_v202001.csv\n",
      "Reading /Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw/trade_data/baci_hs12_y2018_v202001.csv\n",
      "Reading /Users/kaibiaozhu/Documents/GitHub/course5020-finalproject/raw/trade_data/baci_hs12_y2018_v202001.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24025656, 10)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入常用库并读取三年贸易数据\n",
    "import sys\n",
    "import importlib\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pyproj import Geod\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "\n",
    "# 自动解析仓库根目录，兼容从不同工作目录运行\n",
    "NOTEBOOK_DIR = Path.cwd().resolve()\n",
    "PROJECT_ROOT_CANDIDATES = [\n",
    "    NOTEBOOK_DIR,\n",
    "    NOTEBOOK_DIR.parent,\n",
    "    NOTEBOOK_DIR.parent.parent,\n",
    "]\n",
    "PROJECT_ROOT = None\n",
    "for candidate in PROJECT_ROOT_CANDIDATES:\n",
    "    if (candidate / 'raw' / 'trade_data').exists():\n",
    "        PROJECT_ROOT = candidate\n",
    "        break\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError('无法定位 raw/trade_data 目录，请确认当前工作目录位于仓库内。')\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'raw' / 'trade_data'\n",
    "SHAPE_DIR = PROJECT_ROOT / 'raw' / 'countries_shapefile'\n",
    "print('Using project root:', PROJECT_ROOT)\n",
    "\n",
    "\n",
    "def normalize_numeric_code(value: object) -> str | None:\n",
    "    \"\"\"将 ISO 数字代码统一为 3 位字符串（保留字母代码以便后续匹配）。\"\"\"\n",
    "    if value is None or (isinstance(value, float) and np.isnan(value)):\n",
    "        return None\n",
    "    text = str(value).strip()\n",
    "    if text == '':\n",
    "        return None\n",
    "    cleaned = text.replace(',', '')\n",
    "    try:\n",
    "        num = int(float(cleaned))\n",
    "        return f\"{num:03d}\"\n",
    "    except ValueError:\n",
    "        return cleaned.upper()\n",
    "\n",
    "\n",
    "# 定位 2016-2018 的 BACI CSV\n",
    "candidates = [\n",
    "    DATA_DIR / 'baci_hs12_y2016_v202001.csv',\n",
    "    DATA_DIR / 'baci_HS12_y2017_v202001.csv',\n",
    "    DATA_DIR / 'baci_hs12_y2018_v202001.csv',\n",
    "]\n",
    "files = [f for f in candidates if f.exists()]\n",
    "if not files:\n",
    "    files = [\n",
    "        Path(p) for p in glob.glob(str(DATA_DIR / '*.csv'))\n",
    "        if 'baci' in Path(p).name.lower()\n",
    "        and 'country_codes' not in Path(p).name.lower()\n",
    "        and 'product_codes' not in Path(p).name.lower()\n",
    "    ]\n",
    "if not files:\n",
    "    raise FileNotFoundError(f'未在 {DATA_DIR} 下找到 BACI 贸易数据 CSV，请确认文件已解压。')\n",
    "print('Using trade files:', files)\n",
    "\n",
    "# 读取并清洗\n",
    "frames: list[pd.DataFrame] = []\n",
    "for fpath in tqdm(files, desc='Reading trade CSVs'):\n",
    "    print('Reading', fpath)\n",
    "    d = pd.read_csv(fpath, dtype=str)\n",
    "    d.columns = [c.strip().lower() for c in d.columns]\n",
    "    colmap = {}\n",
    "    for c in d.columns:\n",
    "        if c in ['t', 'year', 'y']:\n",
    "            colmap[c] = 't'\n",
    "        if c in ['i', 'exp', 'exporter', 'iso_o', 'iso_o3']:\n",
    "            colmap[c] = 'i'\n",
    "        if c in ['j', 'imp', 'importer', 'iso_d', 'iso_d3']:\n",
    "            colmap[c] = 'j'\n",
    "        if c in ['k', 'hs6', 'prod', 'product']:\n",
    "            colmap[c] = 'k'\n",
    "        if c in ['v', 'value', 'trade_value', 'trade_value_usd']:\n",
    "            colmap[c] = 'v'\n",
    "        if c in ['q', 'qty', 'quantity']:\n",
    "            colmap[c] = 'q'\n",
    "    d = d.rename(columns=colmap)\n",
    "    for required in ['t', 'i', 'j', 'k', 'v']:\n",
    "        if required not in d.columns:\n",
    "            d[required] = np.nan\n",
    "    d['k'] = d['k'].astype(str).str.zfill(6)\n",
    "    for numeric_col in ['v', 'q']:\n",
    "        if numeric_col in d.columns:\n",
    "            d[numeric_col] = (\n",
    "                d[numeric_col]\n",
    "                .astype(str)\n",
    "                .str.replace(',', '')\n",
    "                .replace({'': '0', 'nan': '0'})\n",
    "            )\n",
    "            d[numeric_col] = pd.to_numeric(d[numeric_col], errors='coerce').fillna(0.0)\n",
    "        else:\n",
    "            d[numeric_col] = 0.0\n",
    "    frames.append(d[['t', 'i', 'j', 'k', 'v', 'q']])\n",
    "\n",
    "trade = pd.concat(frames, ignore_index=True, sort=False)\n",
    "trade['t'] = pd.to_numeric(trade['t'], errors='coerce')\n",
    "trade = trade[trade['t'].isin([2016, 2017, 2018])].copy()\n",
    "trade['exporter_code'] = trade['i'].apply(normalize_numeric_code)\n",
    "trade['importer_code'] = trade['j'].apply(normalize_numeric_code)\n",
    "trade['hs6'] = trade['k'].astype(str).str.zfill(6)\n",
    "trade['hs2'] = trade['hs6'].str[:2]\n",
    "trade = trade.dropna(subset=['t', 'exporter_code', 'importer_code', 'hs6'])\n",
    "trade = trade.drop_duplicates()\n",
    "trade['q'] = trade['q'].fillna(0.0)\n",
    "trade = trade.reset_index(drop=True)\n",
    "trade.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecce75dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations after filtering: 24,025,656\n",
      "Rows per year:\n",
      "t\n",
      "2016    7892508\n",
      "2017    8132873\n",
      "2018    8000275\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in key columns:\n",
      "t                0\n",
      "exporter_code    0\n",
      "importer_code    0\n",
      "hs6              0\n",
      "v                0\n",
      "q                0\n",
      "dtype: int64\n",
      "No negative trade values detected.\n",
      "\n",
      "Missing values in key columns:\n",
      "t                0\n",
      "exporter_code    0\n",
      "importer_code    0\n",
      "hs6              0\n",
      "v                0\n",
      "q                0\n",
      "dtype: int64\n",
      "No negative trade values detected.\n",
      "Duplicated rows on (year, exporter, importer, hs6): 0\n",
      "Duplicated rows on (year, exporter, importer, hs6): 0\n"
     ]
    }
   ],
   "source": [
    "# 基本数据质量检查与清洗记录\n",
    "print(f'Total observations after filtering: {len(trade):,}')\n",
    "print('Rows per year:')\n",
    "print(trade['t'].value_counts().sort_index())\n",
    "\n",
    "key_cols = ['t', 'exporter_code', 'importer_code', 'hs6', 'v', 'q']\n",
    "missing_summary = trade[key_cols].isna().sum()\n",
    "print('\\nMissing values in key columns:')\n",
    "print(missing_summary)\n",
    "\n",
    "neg_value_rows = (trade['v'] < 0).sum()\n",
    "if neg_value_rows:\n",
    "    print(f'Warning: {neg_value_rows} rows have negative trade values; please investigate.')\n",
    "else:\n",
    "    print('No negative trade values detected.')\n",
    "\n",
    "dup_keys = ['t', 'exporter_code', 'importer_code', 'hs6']\n",
    "dup_count = trade.duplicated(subset=dup_keys).sum()\n",
    "print(f'Duplicated rows on (year, exporter, importer, hs6): {dup_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd33c4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 - 伙伴数量最多的国家（2016-2018 合计）:\n",
      "display  n_partners\n",
      "    764         220\n",
      "    251         220\n",
      "    616         220\n",
      "    528         220\n",
      "    276         220\n",
      "    381         220\n",
      "    724         220\n",
      "    826         219\n",
      "    203         219\n",
      "    058         219\n",
      "\n",
      "Bottom 10 - 伙伴数量最少的国家（2016-2018 合计）:\n",
      "display  n_partners\n",
      "    530           1\n",
      "    535          36\n",
      "    666          43\n",
      "    652          46\n",
      "    534          50\n",
      "    162          50\n",
      "    574          51\n",
      "    260          52\n",
      "    876          54\n",
      "    583          56\n"
     ]
    }
   ],
   "source": [
    "# 1) 近三年每个国家的贸易伙伴数量（出口与进口合并）\n",
    "pairs = trade[['exporter_code', 'importer_code']].dropna()\n",
    "from collections import defaultdict\n",
    "partners = defaultdict(set)\n",
    "for _, row in pairs.iterrows():\n",
    "    a = row['exporter_code']\n",
    "    b = row['importer_code']\n",
    "    partners[a].add(b)\n",
    "    partners[b].add(a)\n",
    "\n",
    "partner_counts = pd.DataFrame(\n",
    "    [{'country_code': code, 'n_partners': len(counter)} for code, counter in partners.items()]\n",
    ").sort_values('n_partners', ascending=False).reset_index(drop=True)\n",
    "\n",
    "lookup = globals().get('country_lookup')\n",
    "if lookup is not None:\n",
    "    partner_counts = partner_counts.merge(\n",
    "        lookup[['code', 'name']], left_on='country_code', right_on='code', how='left'\n",
    "    )\n",
    "    partner_counts['display'] = partner_counts.apply(\n",
    "        lambda r: f\"{r['country_code']} ({r['name']})\" if pd.notna(r['name']) else r['country_code'], axis=1\n",
    "    )\n",
    "else:\n",
    "    partner_counts['display'] = partner_counts['country_code']\n",
    "\n",
    "print('Top 10 - 伙伴数量最多的国家（2016-2018 合计）:')\n",
    "print(partner_counts.head(10)[['display', 'n_partners']].to_string(index=False))\n",
    "print('\\nBottom 10 - 伙伴数量最少的国家（2016-2018 合计）:')\n",
    "bottom = partner_counts.tail(10).sort_values('n_partners')\n",
    "print(bottom[['display', 'n_partners']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03fe973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country codes 读取失败（encoding=utf-8）：'utf-8' codec can't decode byte 0xf4 in position 1: invalid continuation byte\n",
      "Country codes 读取失败（encoding=utf-8-sig）：'utf-8' codec can't decode byte 0xf4 in position 4141: invalid continuation byte\n",
      "Country codes 试探读取成功，encoding=latin1, preview rows=100\n",
      "Product codes 试探读取成功，encoding=utf-8, preview rows=100\n",
      "\n",
      "Country sample preview:\n",
      "  country_code country_name_abbreviation country_name_full iso_2digit_alpha  \\\n",
      "0            4               Afghanistan       Afghanistan               AF   \n",
      "1            8                   Albania           Albania               AL   \n",
      "2           12                   Algeria           Algeria               DZ   \n",
      "3           16            American Samoa    American Samoa               AS   \n",
      "4           20                   Andorra           Andorra               AD   \n",
      "\n",
      "  iso_3digit_alpha  \n",
      "0              AFG  \n",
      "1              ALB  \n",
      "2              DZA  \n",
      "3              ASM  \n",
      "4              AND  \n",
      "\n",
      "Product sample preview:\n",
      "    code                                        description\n",
      "0  10121           Horses: live, pure-bred breeding animals\n",
      "1  10129  Horses: live, other than pure-bred breeding an...\n",
      "2  10130                                        Asses: live\n",
      "3  10190                            Mules and hinnies: live\n",
      "4  10221           Cattle: live, pure-bred breeding animals\n",
      "\n",
      "编码测试完成，如上预览无报错即可继续执行下一单元。\n"
     ]
    }
   ],
   "source": [
    "# 小规模测试：先检测国家/产品映射文件的编码并预览少量数据\n",
    "ctry_map_path = DATA_DIR / 'country_codes_v202001.csv'\n",
    "prod_map_path = DATA_DIR / 'product_codes_hs12_v202001.csv'\n",
    "COUNTRY_ENCODING = None\n",
    "PRODUCT_ENCODING = None\n",
    "\n",
    "\n",
    "def detect_encoding(path: Path, label: str, test_rows: int = 100):\n",
    "    if not path.exists():\n",
    "        print(f'{label} 文件缺失: {path}')\n",
    "        return None, None\n",
    "    encodings = ['utf-8', 'utf-8-sig', 'latin1', 'ISO-8859-1']\n",
    "    last_error = None\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            sample = pd.read_csv(path, dtype=str, nrows=test_rows, encoding=enc)\n",
    "            print(f'{label} 试探读取成功，encoding={enc}, preview rows={len(sample)}')\n",
    "            return enc, sample\n",
    "        except UnicodeDecodeError as exc:\n",
    "            last_error = exc\n",
    "            print(f'{label} 读取失败（encoding={enc}）：{exc}')\n",
    "    raise RuntimeError(f'{label} 无法用候选编码解析，最后错误: {last_error}')\n",
    "\n",
    "\n",
    "COUNTRY_ENCODING, country_sample = detect_encoding(ctry_map_path, 'Country codes')\n",
    "PRODUCT_ENCODING, product_sample = detect_encoding(prod_map_path, 'Product codes')\n",
    "\n",
    "print('\\nCountry sample preview:')\n",
    "if country_sample is not None:\n",
    "    print(country_sample.head())\n",
    "\n",
    "print('\\nProduct sample preview:')\n",
    "if product_sample is not None:\n",
    "    print(product_sample.head())\n",
    "\n",
    "print('\\n编码测试完成，如上预览无报错即可继续执行下一单元。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 匹配国家 / 产品代码并生成中美的伙伴统计\n",
    "if 'COUNTRY_ENCODING' not in globals():\n",
    "    COUNTRY_ENCODING = 'utf-8'\n",
    "else:\n",
    "    COUNTRY_ENCODING = COUNTRY_ENCODING or 'utf-8'\n",
    "if 'PRODUCT_ENCODING' not in globals():\n",
    "    PRODUCT_ENCODING = 'utf-8'\n",
    "else:\n",
    "    PRODUCT_ENCODING = PRODUCT_ENCODING or 'utf-8'\n",
    "\n",
    "ctry_df = pd.read_csv(ctry_map_path, dtype=str, encoding=COUNTRY_ENCODING) if ctry_map_path.exists() else None\n",
    "prod_df = pd.read_csv(prod_map_path, dtype=str, encoding=PRODUCT_ENCODING) if prod_map_path.exists() else None\n",
    "print('Country codes loaded:', ctry_df.shape if ctry_df is not None else 'Missing file')\n",
    "print('Product codes loaded:', prod_df.shape if prod_df is not None else 'Missing file')\n",
    "\n",
    "\n",
    "def build_country_lookup(df: pd.DataFrame | None) -> pd.DataFrame | None:\n",
    "    if df is None:\n",
    "        return None\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    name_cols = [c for c in df.columns if any(k in c for k in ['name', 'label'])]\n",
    "    id_cols = [c for c in df.columns if any(k in c for k in ['iso', 'code', 'num'])]\n",
    "    if not name_cols or not id_cols:\n",
    "        return None\n",
    "    name_col = name_cols[0]\n",
    "    id_col = id_cols[0]\n",
    "    df['code'] = df[id_col].apply(normalize_numeric_code)\n",
    "    df['name'] = df[name_col].str.strip()\n",
    "    df = df.dropna(subset=['code']).drop_duplicates('code')\n",
    "    df['name_key'] = df['name'].str.upper().str.strip()\n",
    "    return df[['code', 'name', 'name_key']]\n",
    "\n",
    "\n",
    "def build_product_lookup(df: pd.DataFrame | None) -> tuple[dict, pd.DataFrame] | tuple[None, None]:\n",
    "    if df is None:\n",
    "        return None, None\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    code_cols = [c for c in df.columns if 'code' in c or 'hs' in c]\n",
    "    desc_cols = [c for c in df.columns if any(k in c for k in ['desc', 'product', 'label'])]\n",
    "    if not code_cols or not desc_cols:\n",
    "        return None, None\n",
    "    code_col = code_cols[0]\n",
    "    desc_col = desc_cols[0]\n",
    "    df['hs6'] = df[code_col].astype(str).str.zfill(6)\n",
    "    df['hs2'] = df['hs6'].str[:2]\n",
    "    df = df.rename(columns={desc_col: 'product_desc'})\n",
    "    hs2_desc_map = df[['hs2', 'product_desc']].dropna().drop_duplicates('hs2').set_index('hs2')['product_desc'].to_dict()\n",
    "    return hs2_desc_map, df[['hs6', 'hs2', 'product_desc']]\n",
    "\n",
    "\n",
    "country_lookup = build_country_lookup(ctry_df)\n",
    "hs2_desc_map, product_lookup_df = build_product_lookup(prod_df)\n",
    "\n",
    "if country_lookup is not None:\n",
    "    exporter_lookup = country_lookup.rename(columns={'code': 'exporter_code', 'name': 'exporter_name', 'name_key': 'exporter_name_key'})\n",
    "    importer_lookup = country_lookup.rename(columns={'code': 'importer_code', 'name': 'importer_name', 'name_key': 'importer_name_key'})\n",
    "    trade = trade.merge(exporter_lookup[['exporter_code', 'exporter_name']], on='exporter_code', how='left')\n",
    "    trade = trade.merge(importer_lookup[['importer_code', 'importer_name']], on='importer_code', how='left')\n",
    "else:\n",
    "    trade['exporter_name'] = trade['exporter_code']\n",
    "    trade['importer_name'] = trade['importer_code']\n",
    "\n",
    "if product_lookup_df is not None:\n",
    "    trade = trade.merge(\n",
    "        product_lookup_df[['hs6', 'product_desc']], on='hs6', how='left'\n",
    "    )\n",
    "    trade['hs2_desc'] = trade['hs2'].map(hs2_desc_map)\n",
    "else:\n",
    "    trade['product_desc'] = trade['hs6']\n",
    "    trade['hs2_desc'] = trade['hs2']\n",
    "\n",
    "# 辅助函数：根据名称查找国家代码\n",
    "def find_code_by_name(keyword: str, default: str) -> str:\n",
    "    if country_lookup is None:\n",
    "        return default\n",
    "    mask = country_lookup['name'].str.contains(keyword, case=False, na=False)\n",
    "    if mask.any():\n",
    "        return country_lookup.loc[mask, 'code'].iloc[0]\n",
    "    return default\n",
    "\n",
    "china_code = find_code_by_name('China', '156')\n",
    "usa_code = find_code_by_name('United States', '840')\n",
    "japan_code = find_code_by_name('Japan', '392')\n",
    "print('Detected codes -> China:', china_code, 'USA:', usa_code, 'Japan:', japan_code)\n",
    "\n",
    "# 整体贸易额（价值与数量）\n",
    "total_trade_value = trade['v'].sum()\n",
    "total_trade_qty = trade['q'].sum()\n",
    "print(f\"Total trade value 2016-2018: {total_trade_value:,.2f}\")\n",
    "print(f\"Total trade quantity 2016-2018: {total_trade_qty:,.2f}\")\n",
    "\n",
    "\n",
    "def summarize_top_partners(exporter_code: str, label: str, top_n: int = 10) -> pd.DataFrame:\n",
    "    subset = trade[trade['exporter_code'] == exporter_code]\n",
    "    grouped = (\n",
    "        subset.groupby(['importer_code', 'importer_name'], dropna=False)\n",
    "        .agg(export_value=('v', 'sum'), export_quantity=('q', 'sum'))\n",
    "        .sort_values('export_value', ascending=False)\n",
    "        .head(top_n)\n",
    "        .reset_index()\n",
    "    )\n",
    "    print(f\"\\n{label} - Top {top_n} export partners by trade value:\")\n",
    "    print(grouped.to_string(index=False))\n",
    "    return grouped\n",
    "\n",
    "\n",
    "china_top_partners = summarize_top_partners(china_code, 'China')\n",
    "usa_top_partners = summarize_top_partners(usa_code, 'USA')\n",
    "\n",
    "china_exports = trade[trade['exporter_code'] == china_code]\n",
    "china_flow_cols = ['exporter_name', 'importer_name', 'importer_code', 'k', 'product_desc', 't']\n",
    "china_flow_summary = (\n",
    "    china_exports.groupby(china_flow_cols, dropna=False)\n",
    "    .agg(export_value=('v', 'sum'), export_quantity=('q', 'sum'))\n",
    "    .sort_values('export_value', ascending=False)\n",
    "    .head(5)\n",
    "    .reset_index()\n",
    ")\n",
    "print('\\nChina - Top 5 product-year bilateral flows (exports only):')\n",
    "print(china_flow_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 各国出口额 Top10 产品（HS2）以及整体按价值/数量 Top10 商品\n",
    "exports_hs2 = (\n",
    "    trade.groupby(['exporter_code', 'exporter_name', 'hs2', 'hs2_desc'], dropna=False)\n",
    "    .agg(total_value=('v', 'sum'), total_quantity=('q', 'sum'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "def top_products_for_country(code: str, label: str, n: int = 10) -> pd.DataFrame:\n",
    "    subset = exports_hs2[exports_hs2['exporter_code'] == code]\n",
    "    ranked = subset.sort_values('total_value', ascending=False).head(n)\n",
    "    print(f\"\\n{label} - Top {n} HS2 export categories (by value):\")\n",
    "    display_cols = ['hs2', 'hs2_desc', 'total_value', 'total_quantity']\n",
    "    print(ranked[display_cols].to_string(index=False))\n",
    "    return ranked\n",
    "\n",
    "\n",
    "top_products_for_country(china_code, 'China')\n",
    "top_products_for_country(japan_code, 'Japan')\n",
    "top_products_for_country(usa_code, 'USA')\n",
    "\n",
    "overall_by_value = (\n",
    "    trade.groupby(['hs2', 'hs2_desc'], dropna=False)\n",
    "    .agg(total_value=('v', 'sum'))\n",
    "    .sort_values('total_value', ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "overall_by_quantity = (\n",
    "    trade.groupby(['hs2', 'hs2_desc'], dropna=False)\n",
    "    .agg(total_quantity=('q', 'sum'))\n",
    "    .sort_values('total_quantity', ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print('\\nOverall top 10 HS2 categories by trade value:')\n",
    "print(overall_by_value.reset_index().to_string(index=False))\n",
    "print('\\nOverall top 10 HS2 categories by trade quantity:')\n",
    "print(overall_by_quantity.reset_index().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4196671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 计算中国与所有国家重心的距离，并绘制 log-log 散点图\n",
    "shp_files = list((SHAPE_DIR).glob('*.shp'))\n",
    "if not shp_files:\n",
    "    print('找不到 shapefile，请确认路径:', SHAPE_DIR)\n",
    "else:\n",
    "    shp_path = shp_files[0]\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "    print('Loaded shapefile columns:', gdf.columns.tolist())\n",
    "    name_cols = [c for c in gdf.columns if 'name' in c.lower() or 'country' in c.lower()]\n",
    "    name_col = name_cols[0] if name_cols else gdf.columns[0]\n",
    "    iso_cols = [c for c in gdf.columns if any(k in c.lower() for k in ['iso', 'code', 'num'])]\n",
    "    gdf_cent = gdf.to_crs(epsg=4326).copy()\n",
    "    gdf_cent['lon'] = gdf_cent.geometry.centroid.x\n",
    "    gdf_cent['lat'] = gdf_cent.geometry.centroid.y\n",
    "    gdf_cent['name_key'] = gdf_cent[name_col].astype(str).str.upper().str.strip()\n",
    "    if iso_cols:\n",
    "        gdf_cent['shp_code'] = gdf_cent[iso_cols[0]].apply(normalize_numeric_code)\n",
    "    else:\n",
    "        gdf_cent['shp_code'] = None\n",
    "\n",
    "    # 锁定中国重心\n",
    "    china_mask = gdf_cent['name_key'].str.contains('CHINA', case=False, na=False)\n",
    "    if not china_mask.any():\n",
    "        print('警告：在 shapefile 中未找到 China 关键字，使用第一条记录作为近似。')\n",
    "    china_row = gdf_cent[china_mask].iloc[0] if china_mask.any() else gdf_cent.iloc[0]\n",
    "    china_lon, china_lat = float(china_row['lon']), float(china_row['lat'])\n",
    "    geod = Geod(ellps='WGS84')\n",
    "\n",
    "    def gc_distance(row):\n",
    "        _, _, meters = geod.inv(china_lon, china_lat, float(row['lon']), float(row['lat']))\n",
    "        return meters / 1000.0\n",
    "\n",
    "    gdf_cent['dist_km_to_china'] = gdf_cent.apply(gc_distance, axis=1)\n",
    "    shp_lookup = gdf_cent[[name_col, 'name_key', 'lon', 'lat', 'dist_km_to_china', 'shp_code']].rename(columns={name_col: 'shp_name'})\n",
    "\n",
    "    if country_lookup is not None:\n",
    "        shp_lookup = shp_lookup.merge(\n",
    "            country_lookup[['code', 'name', 'name_key']], on='name_key', how='left', suffixes=('_shp', '')\n",
    "        )\n",
    "        shp_lookup['iso_code'] = shp_lookup['code'].fillna(shp_lookup['shp_code'])\n",
    "        shp_lookup['country_name'] = shp_lookup['name'].fillna(shp_lookup['shp_name'])\n",
    "    else:\n",
    "        shp_lookup['iso_code'] = shp_lookup['shp_code']\n",
    "        shp_lookup['country_name'] = shp_lookup['shp_name']\n",
    "\n",
    "    print('\\nSample distances from China to other centroids (km):')\n",
    "    print(shp_lookup[['country_name', 'dist_km_to_china']].dropna().head(10).to_string(index=False))\n",
    "\n",
    "    china_exports_full = (\n",
    "        trade[trade['exporter_code'] == china_code]\n",
    "        .groupby(['importer_code', 'importer_name'], dropna=False)\n",
    "        .agg(export_value=('v', 'sum'), export_quantity=('q', 'sum'))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    china_with_dist = china_exports_full.merge(\n",
    "        shp_lookup[['iso_code', 'dist_km_to_china']], left_on='importer_code', right_on='iso_code', how='left'\n",
    "    )\n",
    "    matched = china_with_dist['dist_km_to_china'].notna().sum()\n",
    "    print(f\"Matched distances for {matched} China export partners out of {len(china_with_dist)}.\")\n",
    "\n",
    "    plot_df = china_with_dist[(china_with_dist['dist_km_to_china'] > 0) & (china_with_dist['export_value'] > 0)].copy()\n",
    "    plot_df['log_dist'] = np.log(plot_df['dist_km_to_china'])\n",
    "    plot_df['log_value'] = np.log(plot_df['export_value'])\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(data=plot_df, x='log_dist', y='log_value', hue='importer_name', legend=False)\n",
    "    plt.xlabel('log(distance km)')\n",
    "    plt.ylabel('log(export value)')\n",
    "    plt.title('China exports: log(distance) vs log(value)')\n",
    "    plt.show()\n",
    "\n",
    "    qty_df = plot_df[plot_df['export_quantity'] > 0].copy()\n",
    "    qty_df['log_quantity'] = np.log(qty_df['export_quantity'])\n",
    "    if not qty_df.empty:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.scatterplot(data=qty_df, x='log_dist', y='log_quantity', hue='importer_name', legend=False)\n",
    "        plt.xlabel('log(distance km)')\n",
    "        plt.ylabel('log(export quantity)')\n",
    "        plt.title('China exports: log(distance) vs log(quantity)')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No positive export quantities available for log quantity scatter plot.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122c92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5020_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
